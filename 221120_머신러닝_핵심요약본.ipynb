{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b447fe3",
   "metadata": {},
   "source": [
    "## 1. 머신러닝 과정\n",
    "### 1) 데이터 확인\n",
    "#### (1) 독립변수, 종속변수 확인 > 연속형/범주형인지?\n",
    "#### (2) 적용가능한 분석 모델 확인\n",
    "##### > 회귀 : 선형(단순, 다중, 다항, 자기회귀), 비선형(의사결정나무, 앙상블, 나이브베이즈, SVM, 인공신경망)\n",
    "##### > 분류  : 로지스틱회귀, 의사결정나무, 앙상블, 나이브베이즈, SVM, 인공신경망\n",
    "##### > 비지도 : 군집분석, 차원축소\n",
    "\n",
    "### 2) 데이터 전처리\n",
    "#### (1) Scale : 표준화, 정규화\n",
    "scaler = StandardScaler() 표준화, or MinMaxScaler() 정규화\n",
    "\n",
    "X_train_Scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_Scaled = scaler.transform(X_test)\n",
    "\n",
    "#### (2) 이상치, 결측치 처리\n",
    "\n",
    "### 3) 데이터 분할\n",
    "#### (1) Train : Test : 7:3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.3, random_state=2022)\n",
    "#### (2) 교차검증방법 적용가능 확인\n",
    "### 4) 데이터 모델학습\n",
    "#### (1) 머신러닝 모델 학습 > 회귀, 분류, 비지도\n",
    "#### (2) 최적모델결정을 위해 하이퍼 파라미터 탐색, 조절\n",
    "### 5) 데이터 성능평가\n",
    "#### (1) 평가셋에 최종모델적용 후 평가셋에 대한 정확도를 성능으로 제시\n",
    "print('test_score : ' , model.score(X_test, y_test))\n",
    "#### (2) 회귀\n",
    "##### > RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "print('RMSE : ', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "#### (3)  분류\n",
    "from sklearn.metrics \n",
    "import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
    "\n",
    "print('confusion_matrix')\n",
    "\n",
    "print(pd.DataFrame(confusion_matrix(y_test, y_pred), index = ['True[0]', 'True[1]'], columns = ['Pred[0]', 'Pred[1]']))\n",
    "\n",
    "print('accuracy_score : ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "print('recall_score : ', recall_score(y_test, y_pred))\n",
    "\n",
    "print('precision_score : ', precision_score(y_test, y_pred))\n",
    "\n",
    "print('classificaion_report')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('ROC_AUC_SOCRE : ', roc_auc_score(y_test, model.predict_proba(X_test)[:,-1]))\n",
    "\n",
    "- binary 분류일 때 : roc_auc_score(Y, clf.predict_proba(X)[:, 1])\n",
    "- 다중 클래스 분류일 때 : roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')\n",
    "- 여러 개의 라벨을 분류할 때 : roc_auc_score(y, y_pred, average=None)\n",
    "\n",
    "print('ROC_CURVE')\n",
    "\n",
    "print(plot_roc_curve(model, X_test, y_test))\n",
    "\n",
    "## 2. 머신러닝 모델 분류\n",
    "### 1) 회귀(레이블 존재, 수치값 예측일 경우)\n",
    "#### (1) '설명력'을 중시 : 릿지/라소/엘라스틱 넷, 의사결정나무\n",
    "#### (2) '정확성'을 중시 \n",
    "##### > 데이터가 크기가 큰 경우 : 랜덤포레스트, 부스팅, 인공신경망\n",
    "##### > 데이터 크기가 작은 경우 :  SVR\n",
    "\n",
    "### 2) 분류\n",
    "#### (1) '설명력'을 중시 : 로지스틱 회귀분석, 의사결정나무\n",
    "#### (2) '정확성'을 중시 \n",
    "##### > 데이터가 크기가 큰 경우 : 랜덤포레스트, 부스팅, 인공신경망, 나이브베이즈, Kernel SVM\n",
    "##### > 데이터 크기가 작은 경우 :  나이브베이즈, Linear SVM\n",
    "\n",
    "\n",
    "## 3. 각 모델 특징, 장/단점\n",
    "### 1) 릿지 모델\n",
    "### 2) 라쏘 모델\n",
    "### 3) 엘라스티 넷  모델\n",
    "### 4) 의사결정트리\n",
    "### 5) 배깅\n",
    "### 6) 랜덤 포레스트\n",
    "### 7) 부스팅\n",
    "### 8) 나이브베이즈\n",
    "### 9) K-NN\n",
    "### 10) SVM\n",
    "### 11) 인공신경망\n",
    "\n",
    "## 4. 전처리\n",
    "### 1) 정규화(릿지, 라소, 엘라스틱 넷)  : 범주형 변수 전처리, Scale 처리 필요\n",
    "### 2) 의사결정나무, 앙상블 : Scale 처리 필요 X, 결측치 처리 필요\n",
    "### 3) 나이브베이즈 \n",
    "#### (1) GaussianNB :  Scale 처리 필요(정규화), 결측치 처리 필요 X(그래도 하자)\n",
    "#### (2) BernoulliNB : 독립변수 0,1 변환 필요(P.281)\n",
    "### 4) KNN : Scale 처리 필요(정규화), 결측치 처리 필요\n",
    "### 5) SVM, 인공신경망 : Scale 처리 필요(표준화)\n",
    "### 6) PCA : Scale 처리 필요(표준화)\n",
    "\n",
    "## 5. Hypter Parameter\n",
    "### 1) 정규화(릿지, 라소, 엘라스틱 넷) \n",
    "param_grid = {'alpha' : (0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.5, 1, 2, 3)\n",
    "\n",
    ",'l1_ratio' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8, 0.9]} # Elastic_Net\n",
    "### 2) 의사결정나무\n",
    "\n",
    "param_grid = {'max_depth' : range(1,40,1), 'min_samples_split': range(2,40,1), # 트리 최대 깊이, 분리될 때 최소 샘플 수\n",
    "\n",
    "      'min_samples_leaf' : range(1,20,1), 'max_leaf_nodes' : range(1,5,1)} # 리프노드 내 최소 샘플 수, 최대 리프노드 수\n",
    "              \n",
    "### 3) 배깅\n",
    "param_grid = {'n_estimators' : range(10,100,10)} # 나무의 수\n",
    "\n",
    "### 4) 부스팅 \n",
    "param_grid = {'learning_rate' : np.arange(0.01, 0.1, 0.02)} # 0.01 ~ 0.1 이전까지 0.02 씩 증가\n",
    "\n",
    "               n_estimators' : range(10,100,10), 부스팅이 종료되는 최대추정기 수\n",
    "               \n",
    "### 5) 랜덤포레스트\n",
    "param_grid = {'max_depth' : range(1,40,1), 'min_samples_split': range(2,40,1), # 트리 최대 깊이, 분리될 때 최소 샘플 수\n",
    "\n",
    "      'min_samples_leaf' : range(1,20,1), 'max_leaf_nodes' : range(1,5,1), # 리프노드 내 최소 샘플 수, 최대 리프노드 수\n",
    "      \n",
    "      'n_estimators' : range(10,100,10)} # 나무의 수\n",
    "### 6) 나이브베이즈\n",
    "model = GaussianNB(priors = [0.5,0.5]) # [0 확률, 1 확률]\n",
    "\n",
    "print('BernoulliNB_class_log_prior_ : ', np.exp(model.class_log_prior_)) # 사전확률 : 미생존 61%, 생존 38%\n",
    "\n",
    "### 7) K-NN\n",
    "#### (1) np.sqrt(len(df))\n",
    "#### (2)  ROC_AUC_SCORE 기준으로 최적의 k찾기\n",
    "k_range = range(1,200)\n",
    "\n",
    "k_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    k_scores.append(roc_auc_score(y_test, model.predict_proba(X_test)[:,-1]))\n",
    "\n",
    "k = k_scores.index(max(k_scores)) + 1 \n",
    "\n",
    "#### (3)  cross_validation 기준으로 최적의 k찾기\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "k_range = range(1,200)\n",
    "\n",
    "k_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    k_scores.append(cross_val_score(model, X_train, y_train, cv = 10, scoring = 'accuracy').mean())\n",
    "    \n",
    "k = k_scores.index(max(k_scores)) + 1 \n",
    "\n",
    "### 8) SVM\n",
    "svc = SVC(probability = True) # ROC_AUC_SCORE\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1 ,0.5, 1, 10, 20, 30], 'gamma':[0.1, 1, 10]}\n",
    "\n",
    "model = GridSearchCV(svc, param_grid, cv = 5 )\n",
    "\n",
    "### 9) 인공신경망\n",
    "\n",
    "mlp = MLPRegressor(random_state = 2022) or MLPClassifier(random_state = 2022) # MLP random_state 지정필요\n",
    "\n",
    "param_grid = {'hidden_layer_sizes' : [40,50,64,72]} # best_estimator가 끝값을 가리키면 범위 조정 필요.\n",
    "\n",
    "param_grid = {'hidden_layer_sizes' : [300,320,350,400]}\n",
    "\n",
    "model = GridSearchCV(mlp, param_grid, cv = 5)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
